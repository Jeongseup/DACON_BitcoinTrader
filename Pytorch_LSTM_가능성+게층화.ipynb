{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35fb535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0+cpu\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "from copy import deepcopy # Add Deepcopy for args\n",
    "import pickle \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    " \n",
    " \n",
    "print(torch.__version__)\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0cf3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read files Complete!\n"
     ]
    }
   ],
   "source": [
    "# read file\n",
    "raw_x_df = pd.read_csv('./data/train_x_df.csv')\n",
    "raw_y_df = pd.read_csv('./data/train_y_df.csv')\n",
    "\n",
    "print('Read files Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0a09f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Train & Test split Complete!\n",
      "    Train set length is (1208, 1208),\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "train_x_df = raw_x_df[raw_x_df.coin_index == 9]\n",
    "train_y_df = raw_y_df[raw_y_df.coin_index == 9]\n",
    "\n",
    "# ================================================= #\n",
    "# test_sample_list = [4176, 601, 1934, 947, 5025]\n",
    "\n",
    "# test set split into X df\n",
    "# test_x_df = raw_x_df[raw_x_df.sample_id.isin(test_sample_list)]\n",
    "# train_x_df =  raw_x_df[~raw_x_df.sample_id.isin(test_sample_list)]\n",
    "\n",
    "# test set split into y df\n",
    "# test_y_df = raw_y_df[raw_y_df.sample_id.isin(test_sample_list)]\n",
    "# train_y_df =  raw_y_df[~raw_y_df.sample_id.isin(test_sample_list)]\n",
    "\n",
    "print(\n",
    "    f'''\n",
    "    Train & Test split Complete!\n",
    "    Train set length is {int(len(train_x_df)/1380), int(len(train_y_df) / 120)},\n",
    "    '''\n",
    "#     Test set length is {int(len(test_x_df) / 1380), int(len(test_y_df) / 120)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f5e7839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    train x shape is (1208, 1380, 10),\n",
      "    train y shape is (1208, 120, 10),\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# ================================================= #\n",
    "def df2d_to_array3d(df_2d):\n",
    "    \n",
    "    # 입력 받은 2차원 데이터 프레임을 3차원 numpy array로 변경하는 함수\n",
    "    feature_size = df_2d.iloc[:,2:].shape[1]\n",
    "    time_size = len(df_2d.time.value_counts())\n",
    "    sample_size = len(df_2d.sample_id.value_counts())\n",
    "    array_3d = df_2d.iloc[:,2:].values.reshape([sample_size, time_size, feature_size])\n",
    "    \n",
    "    return array_3d\n",
    "# ================================================= #\n",
    "\n",
    "# train set\n",
    "train_x_arr = df2d_to_array3d(train_x_df)\n",
    "train_y_arr = df2d_to_array3d(train_y_df)\n",
    "\n",
    "# test set\n",
    "# test_x_arr = df2d_to_array3d(test_x_df)\n",
    "# test_y_arr = df2d_to_array3d(test_y_df)\n",
    "\n",
    "print(\n",
    "    f'''\n",
    "    train x shape is {train_x_arr.shape},\n",
    "    train y shape is {train_y_arr.shape},\n",
    "    '''\n",
    "#     test x shape is {test_x_arr.shape},\n",
    "#     test y shape is {test_y_arr.shape}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "738673cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================= #\n",
    "\n",
    "def simple_exponetial_smoothing_fory(arr, alpha=0.3):\n",
    "    \n",
    "    y_series = list()\n",
    "\n",
    "    for temp_arr in arr:\n",
    "        target_series = temp_arr[:, 1].reshape(-1) # open col is 1 index\n",
    "\n",
    "        smoother = SimpleExpSmoothing(target_series, initialization_method=\"heuristic\").fit(smoothing_level=alpha,optimized=False)\n",
    "        smoothing_series = smoother.fittedvalues\n",
    "\n",
    "        y_series.append(smoothing_series)\n",
    "            \n",
    "    return np.array(y_series)\n",
    "\n",
    "# ================================================= #\n",
    "\n",
    "def simple_exponetial_smoothing_forX(arr, alpha=0.3):\n",
    "    \n",
    "    # initialization\n",
    "    sample_size = int(arr.shape[0])\n",
    "    time_size = int(arr.shape[1])\n",
    "    feature_size = int(arr.shape[2])\n",
    "    \n",
    "    # create empty array\n",
    "    smoothing_arr = np.zeros((sample_size, time_size, feature_size - 1))\n",
    "\n",
    "    for idx, temp_arr in enumerate(arr):\n",
    "        for col in range(1, feature_size): # open col is 1 index\n",
    "            if col < 5:\n",
    "\n",
    "                temp_series = temp_arr[:, col].reshape(-1) \n",
    "                smoother = SimpleExpSmoothing(temp_series, initialization_method=\"heuristic\").fit(smoothing_level=0.3,optimized=False)\n",
    "                temp_smoothing_series = smoother.fittedvalues\n",
    "                smoothing_arr[idx, :, col-1] = temp_smoothing_series\n",
    "\n",
    "            else:\n",
    "                \n",
    "                pass_series = temp_arr[:, col].reshape(-1)\n",
    "                smoothing_arr[idx, :, col-1] = pass_series\n",
    "\n",
    "    return smoothing_arr\n",
    "\n",
    "# ================================================= #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1c84bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeights_FFD(d, size, thres):\n",
    "    w = [1.]  # w의 초깃값 = 1\n",
    "\n",
    "    for k in range(1, size):\n",
    "        w_ = -w[-1] * (d - k + 1) / k  # 식 2)를 사용했다.\n",
    "        if abs(w[-1]) >= thres and abs(w_) <= thres:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            w.append(w_)\n",
    "\n",
    "    # w의 inverse\n",
    "    w = np.array(w[::-1]).reshape(-1, 1)\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "def fracDiff_FFD(series, d, thres=0.002):\n",
    "    '''\n",
    "\n",
    "    Constant width window (new solution)\n",
    "\n",
    "    Note 1: thres determines the cut-off weight for the window\n",
    "\n",
    "    Note 2: d can be any positive fractional, not necessarily bounded [0,1]\n",
    "\n",
    "    '''\n",
    "\n",
    "    # 1) Compute weights for the longest series\n",
    "    w = getWeights_FFD(d, series.shape[0], thres)\n",
    "    width = len(w) - 1\n",
    "\n",
    "    # 2) Apply weights to values\n",
    "    df = []\n",
    "    seriesF = series\n",
    "\n",
    "    for iloc in range(len(w), seriesF.shape[0]):\n",
    "        k = np.dot(w.T[::-1], seriesF[iloc - len(w):iloc])\n",
    "        df.append(k)\n",
    "\n",
    "    df = np.array(df)\n",
    "\n",
    "    return df, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b064560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train set smoothing\n",
    "# train_x_arr = simple_exponetial_smoothing_forX(train_x_arr)\n",
    "# train_y_arr = simple_exponetial_smoothing_fory(train_y_arr)\n",
    "\n",
    "# # test set smoothing \n",
    "# test_x_arr = simple_exponetial_smoothing_forX(test_x_arr)\n",
    "# print('simple exponetial smoothing Complete!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81bff392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newarray = np.zeros((1208,1343,1))\n",
    "# for idx in range(coin9_x_array.shape[0]):\n",
    "#     fdiff, w = fracDiff_FFD(train_x_array[idx,:,1], d=0.35, thres=0.002)\n",
    "#     newarray[idx,:,:] = fdiff\n",
    "    \n",
    "# frac_x_arr, w = fracDiff_FFD(train_x_arr[1, :, 1], d=0.35, thres=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "514fd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_spliter(arr):\n",
    "    \n",
    "    n = len(arr)\n",
    "    num_features = arr.shape[2] - 1\n",
    "    \n",
    "    train_arr = arr[0:int(n*0.8), :, 1:]\n",
    "    val_arr = arr[int(n*0.8):, :, 1:]\n",
    "    \n",
    "    n2 = len(train_arr) + len(val_arr)\n",
    "    \n",
    "    print(\n",
    "    f'''\n",
    "    ======================================================\n",
    "    Origin length is {n}, then total split length is {n2}\n",
    "    ======================================================\n",
    "    train length is {train_arr.shape},\n",
    "    val length is {val_arr.shape},\n",
    "    num_features is ({num_features})\n",
    "    '''\n",
    "    )\n",
    "    \n",
    "    return train_arr, val_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c33ee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    train x shape is (1208, 1380, 10),\n",
      "    train y shape is (1208, 120, 10),\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'''\n",
    "    train x shape is {train_x_arr.shape},\n",
    "    train y shape is {train_y_arr.shape},\n",
    "    '''\n",
    "    \n",
    "#     test x shape is {test_x_arr.shape},\n",
    "#     test y shape is {test_y_arr.shape},\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3de2ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_y = train_y_arr[:, : ,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5c11ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\venv\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(open_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ffa9f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_y_min = open_y.min()\n",
    "open_y_max = open_y.max()\n",
    "\n",
    "open_y = (open_y - open_y_min) / (open_y_max - open_y_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e981290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\venv\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(open_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96003793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & val set\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_x_arr[:, :, 1:], train_y_arr[:, :, 1], test_size=0.2, shuffle=False)\n",
    "\n",
    "# test set\n",
    "# test_X = test_x_arr[:, :, 1:] # open col\n",
    "# test_y = test_y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb3b376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================\n",
      "Origin length is 1208, then total split length is 966\n",
      "======================================================\n",
      "train X length is (966, 1380, 9), train y length is (966, 120),\n",
      "val X length is (242, 1380, 9), val y length is (242, 120),\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f'''\n",
    "======================================================\n",
    "Origin length is {len(train_x_arr)}, then total split length is {len(train_X)}\n",
    "======================================================\n",
    "train X length is {train_X.shape}, train y length is {train_y.shape},\n",
    "val X length is {val_X.shape}, val y length is {val_y.shape},\n",
    "'''\n",
    "# test X length is {test_X.shape}, test y length is {test_y.shape}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9581e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_mean = train_X.mean(axis=(0, 1))\n",
    "train_x_std = train_X.std(axis=(0, 1))\n",
    "\n",
    "train_X = (train_X - train_x_mean) / train_x_std\n",
    "val_X = (val_X - train_x_mean) / train_x_std\n",
    "# test_X = (test_X - train_x_mean) / train_x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bedde48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n"
     ]
    }
   ],
   "source": [
    "# ====== initialization\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"device is\",args.device)\n",
    "\n",
    "seed = 777\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "# ====== Model Capacity options ===== #\n",
    "args.input_dim = 9\n",
    "args.hidden_dim = 50\n",
    "args.output_dim = 1\n",
    "args.n_layers = 1\n",
    "args.batch_size = 8\n",
    "args.dropout = 0.2\n",
    "args.use_bn = True\n",
    "\n",
    "# ====== Dataset Generating options ====== #\n",
    "args.x_frames = 255\n",
    "args.y_frames = 120\n",
    "\n",
    "# ====== Model training options ===== #\n",
    "args.num_epoch = 50\n",
    "args.learning_rate = 0.0001\n",
    "args.L2_rate = 0.00001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94f62eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    ''' Dataset Generate'''\n",
    "    def __init__(self, X_arr, y_arr, x_frames):\n",
    "    \n",
    "        self.X_arr = X_arr\n",
    "        self.y_arr = y_arr\n",
    "        self.x_frames = x_frames\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Input indices: {self.X_arr.shape}',\n",
    "            f'Label indices: {len(self.y_arr)}',\n",
    "            f'Current column name(s): {self.x_frames}'\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_arr)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        X = self.X_arr[idx, -self.x_frames:, :]\n",
    "        y = self.y_arr[idx, :]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c71beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout, use_bn):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.use_bn = use_bn \n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        self.regressor = self.make_regressor()\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_dim))\n",
    "    \n",
    "    def make_regressor(self):\n",
    "        layers = []\n",
    "        if self.use_bn:\n",
    "            layers.append(nn.BatchNorm1d(self.hidden_dim))\n",
    "        layers.append(nn.Dropout(self.dropout))\n",
    "        \n",
    "        layers.append(nn.Linear(self.hidden_dim, 200))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(200, self.output_dim))\n",
    "        regressor = nn.Sequential(*layers)\n",
    "        return regressor\n",
    "    \n",
    "    def forward(self, X):\n",
    "        lstm_out, self.hidden = self.lstm(X)\n",
    "        y_pred = self.regressor(lstm_out[-1].view(X.shape[1], -1))\n",
    "        return y_pred\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "def train(model, partition, optimizer, loss_fn, args):\n",
    "    ''' model training '''\n",
    "   \n",
    "    # data load\n",
    "    trainloader = DataLoader(partition['train'],\n",
    "                             batch_size = args.batch_size,\n",
    "                             shuffle = True, drop_last = True)\n",
    "    \n",
    "    # model's mode setting\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, (X, y) in enumerate(trainloader):\n",
    "    \n",
    "        X = X.transpose(0, 1).float().to(args.device)\n",
    "        y_true = y.float().to(args.device)\n",
    "        \n",
    "#         print(X.shape, y_true.shape)\n",
    "        \n",
    "        # zero the gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model.hidden = model.init_hidden(X.shape[1])\n",
    "\n",
    "        y_pred = model(X)\n",
    "#         print(y_pred.shape)\n",
    "        \n",
    "        loss = loss_fn(y_true.view(-1), y_pred.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # get the batch loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    # train_loss = train_loss*10E5\n",
    "    return model, train_loss\n",
    "\n",
    "\n",
    "def validate(model, partition, loss_fn, args):\n",
    "    ''' model validate '''\n",
    "    \n",
    "    # data load\n",
    "    valloader = DataLoader(partition['val'], \n",
    "                           batch_size = args.batch_size, \n",
    "                           shuffle = False, drop_last = True)\n",
    "    \n",
    "    # model's mode setting\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    # evaluate\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(valloader):\n",
    "            \n",
    "            X = X.transpose(0, 1).float().to(args.device)\n",
    "            y_true = y.float().to(args.device)\n",
    "            \n",
    "            model.hidden = model.init_hidden(X.shape[1])\n",
    "            # en-decoder outputs tensor \n",
    "            y_pred = model(X)\n",
    "            # compute the loss \n",
    "            loss = loss_fn(y_true.view(-1), y_pred.view(-1))\n",
    "\n",
    "            # get the batch loss\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss = val_loss / len(valloader)\n",
    "    # val_loss = val_loss * 10E5\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "\n",
    "def experiment(partition, args):\n",
    "\n",
    "\n",
    "    model = LSTM(args.input_dim, args.hidden_dim, args.y_frames, args.n_layers, args.dropout, args.use_bn)\n",
    "    model.to(args.device)\n",
    "    \n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.L2_rate)\n",
    "    \n",
    "    # epoch-wise loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(args.num_epoch):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        model, train_loss = train(model, partition, optimizer, loss_fn, args)\n",
    "        val_loss = validate(model, partition, loss_fn, args)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # add epoch loss\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print('Epoch {},Loss(train/val) {:.3f}/{:.3f}. Took {:.2f} sec'.format(epoch+1, train_loss * 10E3, val_loss * 10E3, end_time-start_time))\n",
    "    \n",
    "    \n",
    "    # ======= Add Result to Dictionary ======= #\n",
    "    result = {}\n",
    "    \n",
    "    result['train_losses'] = train_losses #epoch 수에 의존\n",
    "    result['val_losses'] = val_losses \n",
    "     \n",
    "    return vars(args), result, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c82ac6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = WindowGenerator(train_X, train_y, x_frames = args.x_frames)\n",
    "valset = WindowGenerator(val_X, val_y, x_frames = args.x_frames)\n",
    "# testset = WindowGenerator(test_X, test_y, x_frames = args.x_frames)\n",
    "\n",
    "partition = {'train': trainset, 'val':valset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7069f619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(L2_rate=1e-05, batch_size=8, device='cpu', dropout=0.2, hidden_dim=50, input_dim=9, learning_rate=0.0001, n_layers=1, num_epoch=50, output_dim=1, use_bn=True, x_frames=255, y_frames=120)\n",
      "Epoch 1,Loss(train/val) 6409.901/3685.064. Took 14.78 sec\n",
      "Epoch 2,Loss(train/val) 1984.229/1940.992. Took 17.43 sec\n",
      "Epoch 3,Loss(train/val) 1175.681/1391.815. Took 20.80 sec\n",
      "Epoch 4,Loss(train/val) 853.994/1047.556. Took 21.01 sec\n",
      "Epoch 5,Loss(train/val) 678.974/772.183. Took 16.54 sec\n",
      "Epoch 6,Loss(train/val) 591.891/504.728. Took 15.45 sec\n",
      "Epoch 7,Loss(train/val) 515.044/703.341. Took 14.83 sec\n",
      "Epoch 8,Loss(train/val) 463.351/616.744. Took 13.80 sec\n",
      "Epoch 9,Loss(train/val) 445.263/510.318. Took 13.82 sec\n",
      "Epoch 10,Loss(train/val) 389.533/716.502. Took 14.19 sec\n",
      "Epoch 11,Loss(train/val) 375.192/475.140. Took 13.33 sec\n",
      "Epoch 12,Loss(train/val) 339.000/370.972. Took 12.90 sec\n",
      "Epoch 13,Loss(train/val) 328.726/519.603. Took 12.64 sec\n",
      "Epoch 14,Loss(train/val) 292.243/359.306. Took 13.32 sec\n",
      "Epoch 15,Loss(train/val) 268.082/290.763. Took 12.97 sec\n",
      "Epoch 16,Loss(train/val) 284.418/383.720. Took 13.46 sec\n",
      "Epoch 17,Loss(train/val) 245.110/367.909. Took 12.81 sec\n",
      "Epoch 18,Loss(train/val) 231.268/383.805. Took 12.63 sec\n",
      "Epoch 19,Loss(train/val) 249.870/372.635. Took 12.74 sec\n",
      "Epoch 20,Loss(train/val) 206.183/497.929. Took 14.87 sec\n",
      "Epoch 21,Loss(train/val) 225.832/254.890. Took 13.76 sec\n",
      "Epoch 22,Loss(train/val) 199.920/389.725. Took 13.14 sec\n",
      "Epoch 23,Loss(train/val) 178.917/257.039. Took 15.19 sec\n",
      "Epoch 24,Loss(train/val) 185.663/326.848. Took 13.20 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-1629c9e68dc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msetting\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-db9b60bd435e>\u001b[0m in \u001b[0;36mexperiment\u001b[1;34m(partition, args)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-db9b60bd435e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, partition, optimizer, loss_fn, args)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\venv\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(args)\n",
    "setting, result, model = experiment(partition, deepcopy(args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
