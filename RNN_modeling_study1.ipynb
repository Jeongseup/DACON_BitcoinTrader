{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# others\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "from copy import deepcopy # Add Deepcopy for args\n",
    "import pickle \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 9)\n",
    "\n",
    "# read file\n",
    "df = pd.read_hdf('./data/merged_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' greedy feature handleing'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' greedy feature handleing'''\n",
    "# test_df = train_x_df[train_x_df['volume'] != 0]\n",
    "# test_df['rest_asset'] = test_df['volume'] - test_df['tb_base_av']\n",
    "# test_df['greedy'] = test_df['tb_base_av'] / test_df['volume']\n",
    "\n",
    "# test_df2 = test_df[['time', 'coin_index', 'open', 'high', 'low', 'close', 'volume', 'trades', 'tb_base_av','rest_asset', 'greedy']]\n",
    "# test_df2[['coin_index','trades', 'volume', 'tb_base_av','rest_asset', 'greedy']].head()\n",
    "# test_df2[test_df2['greedy'] == 1][['coin_index','trades', 'volume', 'tb_base_av','rest_asset', 'greedy']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = df[df.sample_id < 100]\n",
    "# val_df = df[(df.sample_id >= 1000) & (df.sample_id < 1108)]\n",
    "# test_df = df[df.sample_id >= 1108]\n",
    "\n",
    "# 개수 체크\n",
    "# print(\n",
    "#     f'''\n",
    "#     train set is {len(train_df) / 1500}\n",
    "#     val set is {len(val_df) / 1500}\n",
    "#     test set is {len(test_df)/1500}\n",
    "#     '''\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Generating Dataset ====== #\n",
    "\n",
    "def data_generate(dataframe, x_frames, y_frames, print_mode = False):\n",
    "\n",
    "    ''' 설명 생략 '''\n",
    "\n",
    "    # grouping\n",
    "    grouped_df = dataframe.groupby('sample_id')\n",
    "    \n",
    "    # export unique sample ids\n",
    "    unique_sample_id_list = grouped_df.sample_id.unique()\n",
    "\n",
    "    # create new lists\n",
    "    X, y = list(), list()\n",
    "\n",
    "    ''' 샘플 하나 선택 loop '''\n",
    "    for sample_id in unique_sample_id_list:\n",
    "        \n",
    "        # get one sample_id in sample list\n",
    "        temp_sample_id = sample_id.item()\n",
    "\n",
    "        # get one group by temp_sample_id\n",
    "        temp_df = grouped_df.get_group(temp_sample_id)\n",
    "\n",
    "        # 한 샘플당 몇 개의 arrset가 나오는 지 확인\n",
    "        count = 0\n",
    "        split_length = len(temp_df) - (x_frames + y_frames) + 1\n",
    "        \n",
    "        ''' 한 샘플 내 데이터 split loop '''\n",
    "        for time_idx in range(split_length):\n",
    "            \n",
    "            # index 변경\n",
    "            time_idx += x_frames\n",
    "            \n",
    "            # temp_data select\n",
    "            temp_arr = temp_df.iloc[time_idx - x_frames : time_idx + y_frames, 3:].values\n",
    "\n",
    "            # get values\n",
    "            temp_x = temp_arr[:x_frames, :]\n",
    "            temp_y = temp_arr[x_frames:, :]\n",
    "\n",
    "#             # 2d to 3d -> (255, 12) to (1, 255, 12) / (120, 12) to (1, 120, 12)\n",
    "#             temp_3d_x = np.expand_dims(temp_2d_x, axis = 0)\n",
    "#             temp_3d_y = np.expand_dims(temp_2d_y, axis = 0)\n",
    "            \n",
    "            # appending\n",
    "            X.append(temp_x)\n",
    "            y.append(temp_y)\n",
    "            \n",
    "            # counter printing\n",
    "            count += 1\n",
    "            if (count == split_length) & (print_mode == True):\n",
    "                print(f'현재 sample id : {temp_sample_id}')\n",
    "                print(f'{temp_sample_id}번째 sample의 생성 array수 : {count}')\n",
    "            \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Generating Dataset ====== #\n",
    "\n",
    "def open_data_generate(dataframe, col_name, x_frames, y_frames, print_mode = False):\n",
    "\n",
    "    ''' 설명 생략 '''\n",
    "\n",
    "    # grouping\n",
    "    grouped_df = dataframe.groupby('sample_id')\n",
    "    \n",
    "    # export unique sample ids\n",
    "    unique_sample_id_list = grouped_df.sample_id.unique()\n",
    "\n",
    "    # create new lists\n",
    "    X, y = list(), list()\n",
    "\n",
    "    ''' 샘플 하나 선택 loop '''\n",
    "    for sample_id in unique_sample_id_list:\n",
    "        \n",
    "        # get one sample_id in sample list\n",
    "        temp_sample_id = sample_id.item()\n",
    "\n",
    "        # get one group by temp_sample_id\n",
    "        temp_series = grouped_df.get_group(temp_sample_id)[col_name]\n",
    "\n",
    "        # 한 샘플당 몇 개의 arrset가 나오는 지 확인\n",
    "        count = 0\n",
    "        split_length = len(temp_series) - (x_frames + y_frames) + 1\n",
    "        \n",
    "        ''' 한 샘플 내 데이터 split loop '''\n",
    "        for time_idx in range(split_length):\n",
    "            \n",
    "            # index 변경\n",
    "            time_idx += x_frames\n",
    "            \n",
    "            # temp_data select\n",
    "            temp_arr = temp_series[time_idx - x_frames : time_idx + y_frames]\n",
    "\n",
    "            # get values\n",
    "            temp_x, temp_y = temp_arr.iloc[:x_frames].values, temp_arr.iloc[x_frames:].values\n",
    "\n",
    "            # appending\n",
    "            X.append(temp_x)\n",
    "            y.append(temp_y)\n",
    "            \n",
    "            # counter printing\n",
    "            count += 1\n",
    "            if (count == split_length) & (print_mode == True):\n",
    "                print(f'현재 sample id : {temp_sample_id}')\n",
    "                print(f'{temp_sample_id}번째 sample의 생성 array수 : {count}')\n",
    "            \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 sample id : 0\n",
      "0번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 1\n",
      "1번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 2\n",
      "2번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 3\n",
      "3번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 4\n",
      "4번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 5\n",
      "5번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 6\n",
      "6번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 7\n",
      "7번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 8\n",
      "8번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 9\n",
      "9번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 10\n",
      "10번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 11\n",
      "11번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 12\n",
      "12번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 13\n",
      "13번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 14\n",
      "14번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 15\n",
      "15번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 16\n",
      "16번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 17\n",
      "17번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 18\n",
      "18번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 19\n",
      "19번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 20\n",
      "20번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 21\n",
      "21번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 22\n",
      "22번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 23\n",
      "23번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 24\n",
      "24번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 25\n",
      "25번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 26\n",
      "26번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 27\n",
      "27번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 28\n",
      "28번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 29\n",
      "29번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 30\n",
      "30번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 31\n",
      "31번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 32\n",
      "32번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 33\n",
      "33번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 34\n",
      "34번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 35\n",
      "35번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 36\n",
      "36번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 37\n",
      "37번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 38\n",
      "38번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 39\n",
      "39번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 40\n",
      "40번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 41\n",
      "41번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 42\n",
      "42번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 43\n",
      "43번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 44\n",
      "44번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 45\n",
      "45번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 46\n",
      "46번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 47\n",
      "47번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 48\n",
      "48번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 49\n",
      "49번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 50\n",
      "50번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 51\n",
      "51번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 52\n",
      "52번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 53\n",
      "53번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 54\n",
      "54번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 55\n",
      "55번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 56\n",
      "56번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 57\n",
      "57번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 58\n",
      "58번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 59\n",
      "59번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 60\n",
      "60번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 61\n",
      "61번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 62\n",
      "62번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 63\n",
      "63번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 64\n",
      "64번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 65\n",
      "65번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 66\n",
      "66번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 67\n",
      "67번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 68\n",
      "68번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 69\n",
      "69번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 70\n",
      "70번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 71\n",
      "71번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 72\n",
      "72번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 73\n",
      "73번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 74\n",
      "74번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 75\n",
      "75번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 76\n",
      "76번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 77\n",
      "77번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 78\n",
      "78번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 79\n",
      "79번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 80\n",
      "80번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 81\n",
      "81번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 82\n",
      "82번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 83\n",
      "83번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 84\n",
      "84번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 85\n",
      "85번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 86\n",
      "86번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 87\n",
      "87번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 88\n",
      "88번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 89\n",
      "89번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 90\n",
      "90번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 91\n",
      "91번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 92\n",
      "92번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 93\n",
      "93번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 94\n",
      "94번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 95\n",
      "95번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 96\n",
      "96번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 97\n",
      "97번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 98\n",
      "98번째 sample의 생성 array수 : 1470\n",
      "현재 sample id : 99\n",
      "99번째 sample의 생성 array수 : 1470\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = open_data_generate(train_df,col_name ='open', x_frames = 30, y_frames = 1, print_mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x shape is (147000, 30) \n",
      "train y shape is (147000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'train x shape is {train_x.shape} \\n'\n",
    "    f'train y shape is {train_y.shape}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(30, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 45888/147000 [========>.....................] - ETA: 1:16 - loss: 0.0095"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-fc300f335a07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\venv\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# fit model\n",
    "model.fit(train_x, train_y, epochs=200, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy arrary conversion\n",
    "\n",
    "def df2d_to_array3d(df_2d):\n",
    "    # 입력 받은 2차원 데이터 프레임을 3차원 numpy array로 변경하는 함수\n",
    "    feature_size = df_2d.iloc[:,2:].shape[1]\n",
    "    time_size = len(df_2d.time.value_counts())\n",
    "    sample_size = len(df_2d.sample_id.value_counts())\n",
    "\n",
    "    # 2위 팀에서 임의로 넣어둠\n",
    "    # sample_index = df_2d.sample_id.value_counts().index\n",
    "    array_3d = df_2d.iloc[:,2:].values.reshape([sample_size, time_size, feature_size])\n",
    "    return array_3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'''\n",
    "    {df.high.max()}\n",
    "    {df.low.max()}\n",
    "    {df.open.max()}\n",
    "    {df.close.max()}\n",
    "    \n",
    "    \n",
    "    {df.high.min()}\n",
    "    {df.low.min()}\n",
    "    {df.open.min()}\n",
    "    {df.close.min()}\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ''' high - low = 변동폭 \\n'''\n",
    "    ''' 음봉양봉 구분 추가 가능'''\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
